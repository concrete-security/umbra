services:
  vllm:
    image: vllm/vllm-openai:v0.11.0
    container_name: vllm
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - huggingface-cache:/root/.cache/huggingface
    runtime: nvidia
    # No external ports - internal access only
    expose:
      - "8000"
    networks:
      - vllm
    command: >
      --model openai/gpt-oss-120b
      --tensor-parallel-size 1
      --gpu-memory-utilization 0.95
      --max-model-len 131072
      --max-num-seqs 8
      --reasoning-parser openai_gptoss
      --async-scheduling
    restart: unless-stopped
    healthcheck:
      start_period: 1h30m # Allow up to 90 minutes for initial model loading
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  proxy_api:
      build:
        context: ./vllm_proxy
        dockerfile: Dockerfile
      container_name: proxy_api
      depends_on:
        vllm:
          condition: service_healthy
      networks:
        - vllm
        - proxy_api
      environment:
        - BASE_VLLM_URL=http://vllm:8000
        - HOST=0.0.0.0
        - PORT=7000
      # No external ports - internal access only
      expose:
        - "{PORT}"
      restart: unless-stopped

  # Combined Nginx reverse proxy and Certificate Manager
  nginx-cert-manager:
    image: ghcr.io/concrete-security/cert-manager:latest
    container_name: nginx-cert-manager
    ports:
      - "80:80"
      - "443:443"
    environment:
      - DOMAIN=vllm.concrete-security.com
      - DEV_MODE=false
      - LETSENCRYPT_STAGING=false
      # Used to versionize accounts: can change account by using another env variable
      # Useful in case an account reaches a rate limit
      - LETSENCRYPT_ACCOUNT_VERSION=v1
    volumes:
      - tls-certs-keys:/etc/nginx/ssl/
      - /var/run/dstack.sock:/var/run/dstack.sock
    networks:
      - proxy_api
      - attestation
    restart: unless-stopped

  # TDX Attestation service
  attestation-service:
    image: ghcr.io/concrete-security/attestation-service:latest
    container_name: attestation-service
    environment:
      - HOST=0.0.0.0
      - PORT=8080
      # Keep it to 1 if you want replication at the container orchestration level (see deploy.replicas)
      - WORKERS=1
    volumes:
      - /var/run/dstack.sock:/var/run/dstack.sock
    expose:
      - "8080"
    networks:
      - attestation
    restart: unless-stopped
    deploy:
      mode: replicated
      # Keep it to 1 if you want replication at the process level (see env.WORKERS)
      replicas: 1

networks:
  vllm:
    name: vllm
    driver: bridge
  proxy_api:
    driver: bridge
  attestation:
    driver: bridge

volumes:
  # Used to store huggingface models
  huggingface-cache:
  # TLS certificates and keys
  tls-certs-keys:
