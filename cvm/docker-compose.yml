services:
  vllm_service:
    image: vllm/vllm-openai:v0.11.0
    container_name: vllm_container
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]
    volumes:
      - models:/models
      - huggingface-cache:/root/.cache/huggingface
      # - /mnt/disk1/tee_models:/mnt/disk1/tee_models
      # - /mnt/disk1/huggingface:/root/.cache/huggingface
    # No external ports - internal access only
    expose:
      - "8000"
    networks:
      - vllm
    command: >
      --model openai/gpt-oss-120b
      --tensor-parallel-size 1
      --gpu-memory-utilization 0.95
      --max-model-len 131072
      --max-num-seqs 8
      --reasoning-parser openai_gptoss
      --async-scheduling
    restart: unless-stopped
    healthcheck:
      start_period: 1h30m # Allow up to 90 minutes for initial model loading
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx reverse proxy with HTTPS
  nginx:
    image: nginx
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - tls-certs-keys:/etc/nginx/ssl:ro
    configs:
      - source: nginx-default-conf
        target: /etc/nginx/conf.d/default.conf
        mode: 0444
    networks:
      - vllm
    depends_on:
      cert-manager:
        condition: service_healthy
        restart: true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "-k", "https://nginx/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Certificate and key management service
  cert-manager:
    image: ghcr.io/concrete-security/cert-manager:latest
    container_name: cert-manager
    environment:
      - DOMAIN=vllm.concrete-security.com
      - DEV_MODE=true
    volumes:
      - tls-certs-keys:/certs
      - /var/run/dstack.sock:/var/run/dstack.sock
    restart: unless-stopped

networks:
  vllm:
    driver: bridge

volumes:
  # Used to store huggingface models
  huggingface-cache:
  # TLS certificates and keys
  tls-certs-keys:

configs:
  nginx-default-conf:
    content: |
      # Upstream for VLLM service
      upstream vllm_backend {
          server vllm_service:8000;
      }

      # HTTP server for ACME challenges and redirect
      server {
          listen 80;
          server_name _;

          # ACME challenge endpoint for Let's Encrypt
          # location /.well-known/acme-challenge/ {
          #     root /acme-challenge/;
          #     try_files $$uri =404;
          # }

          # Redirect all other HTTP requests to HTTPS
          location / {
              return 301 https://$$host$$request_uri;
          }
      }

      # HTTPS server
      server {
          listen 443 ssl http2;
          server_name _;

          # SSL certificate and key
          ssl_certificate /etc/nginx/ssl/cert.pem;
          ssl_certificate_key /etc/nginx/ssl/key.pem;

          # ACME challenge endpoint for Let's Encrypt
          # location /.well-known/acme-challenge/ {
          #     root /acme-challenge/;
          #     try_files $$uri =404;
          # }

          # Health check endpoint
          location = /health {
              access_log off;
              return 200 "healthy\n";
              add_header Content-Type text/plain;
          }

          # Proxy to VLLM service
          location / {
              proxy_pass http://vllm_backend;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
              proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $$scheme;
          }
      }
