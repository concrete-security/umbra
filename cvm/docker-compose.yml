services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - huggingface-cache:/root/.cache/huggingface
    runtime: nvidia
    # No external ports - internal access only
    expose:
      - "8000"
    networks:
      - vllm
    command: >
      --model openai/gpt-oss-120b
      --tensor-parallel-size 1
      --gpu-memory-utilization 0.95
      --max-model-len 131072
      --max-num-seqs 8
      --reasoning-parser openai_gptoss
      --async-scheduling
      --allowed-origins []
    restart: unless-stopped
    healthcheck:
      start_interval: 1h30m # Allow up to 90 minutes for initial model loading
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Combined Nginx reverse proxy and Certificate Manager
  nginx-cert-manager:
    image: ghcr.io/concrete-security/cert-manager@sha256:b86ca2fef7d3669a619c3bf08f4c20ca8ff4d73974e1f7522fe6618635ef8175
    container_name: nginx-cert-manager
    ports:
      - "80:80"
      - "443:443"
    environment:
      - DOMAIN=vllm.concrete-security.com
      - DEV_MODE=false
      - LETSENCRYPT_STAGING=false
      # Used to versionize accounts: can change account by using another env variable
      # Useful in case an account reaches a rate limit
      - LETSENCRYPT_ACCOUNT_VERSION=v1
      # Force removal of existing certificate files on startup
      - FORCE_RM_CERT_FILES=false
      # Set log level
      - LOG_LEVEL=INFO
    volumes:
      - tls-certs-keys:/etc/nginx/ssl/
      - /var/run/dstack.sock:/var/run/dstack.sock
    networks:
      - vllm
      - attestation
    restart: unless-stopped

  # TDX Attestation service
  attestation-service:
    image: ghcr.io/concrete-security/attestation-service@sha256:08744809468691ce0a3b37a388b95080a6ec64b2f946505c30ed7de622454a97
    container_name: attestation-service
    environment:
      - HOST=0.0.0.0
      - PORT=8080
      # Keep it to 1 if you want replication at the container orchestration level (see deploy.replicas)
      - WORKERS=1
    volumes:
      - /var/run/dstack.sock:/var/run/dstack.sock
    expose:
      - "8080"
    networks:
      - attestation
    restart: unless-stopped
    deploy:
      mode: replicated
      # Keep it to 1 if you want replication at the process level (see env.WORKERS)
      replicas: 1

networks:
  vllm:
    driver: bridge
  attestation:
    driver: bridge

volumes:
  # Used to store huggingface models
  huggingface-cache:
  # TLS certificates and keys
  tls-certs-keys:
